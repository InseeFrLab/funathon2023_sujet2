[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Funathon 2023 - Sujet 2",
    "section": "",
    "text": "Contexte et description du sujet\nCe sujet s’articule autour de la question suivante : dans quelle mesure notre système actuel de cultures est-il exposé au changement climatique ? Il est composé de plusieurs applications décrites ci-dessous et disponibles sur les pages suivantes. Ces applications sont des points de départ, tout comme les solutions proposées - n’hésitez pas à aller plus loin !\nAvec ce sujet, vous allez pouvoir :\n\nTravailler avec le langage R;\nManipuler des données spatiales : vecteurs et rasters avec les packages sf, terra, stars;\nUtiliser une base de données PostgreSQL et son extension PostGIS;\nCréer des visualisations avec ggplot2;\nDévelopper un tableau de bord interactif avec shiny;\nUtiliser le lissage spatial pour synthétiser des données géographiques avec btb;\nEstimer des tendances avec un modèle linéaire.\n\n\nMise en route\nAvant tout, il faut qu’une personne dans l’équipe commence par fork ce dépôt de code sur Gitlab, et donne les droits d’écriture sur le fork à ses partenaires (tout ceci est expliqué dans cette vidéo de présentation du Funathon). Tous les membres de l’équipe peuvent maintenant ouvrir un service RStudio sur le SSP Cloud et créer un nouveau projet à partir du dépôt forké (File &gt; New project &gt; Version Control &gt; Git), sur lequel ils pourront pousser leur code !\nPour disposer de toutes les librairies nécessaires, il est possible de faire toutes les installations avec renv::restore() (~10 min). Bien sûr si vous avez besoin de packages supplémentaires à un moment donné, n’hésitez pas à les installer !\nPour traiter le sujet, nous vous laissons libres de vous organiser comme vous le souhaitez. Vous pouvez par exemple créer vous-mêmes vos scripts (par exemple un script par application et par personne, avant de mutualiser les avancées - sauf pour l’application shiny où nous suggérons explicitement de créer plusieurs scripts à placer dans un répertoire ad hoc), et lorsque vous en ressentez le besoin aller tirer des bouts de code des solutions que nous proposons sur ce site.\n\n\n\n\n\n\nNote sur l’accès à l’espace de stockage\n\n\n\nSi vous lancez un service interactif RStudio au cours de la première journée et que utilisez le même lors de la seconde journée, vos identifiants permettant l’accès à l’espace de stockage du SSP Cloud auront expiré. Vous trouverez sur cette page des scripts (R notamment) permettant de mettre à jour les variables d’environnement concernées.\n\n\n\n\nLes données utilisées\nCe sujet propose de manipuler :\n\nLe Registre Parcellaire Graphique (RPG);\nDes données du Drias de simulation de l’évolution climatique pour le siècle en cours sur la France;\nDes données ERA5 agro-météorologiques de surface quotidiens pour la période allant de 1979 à aujourd’hui.\n\n\n\nEtape 0 (optionnel) : Création d’une base de données PostgreSQL\nLes données du RPG étant volumineuses, il faut pouvoir les requêter depuis une base de données. Les gentils organisateurs vous ont déjà préparé une base de données PostgreSQL (avec l’extension PostGIS) prête à l’emploi pour ce sujet. Néanmoins, nous vous expliquons comment procéder si vous souhaitez être en mesure de le faire vous-mêmes sur la plateforme SSP Cloud.\n\n\nEtape 1 : Première manipulation du RPG\nL’objectif de cette étape est d’effectuer des premières requêtes géographiques permettant d’examiner les cultures à proximité d’un point géographique donné, de comparer la composition observée avec les compositions départementale et nationale. Pour aller plus loin, nous proposons de développer une interface graphique de type tableau de bord permettant d’obtenir ces informations interactivement en cliquant sur une carte.\n\n\nEtape 2 : Exposition des cultures au déficit de précipitations\nCette deuxième étape est fortement inspirée de l’excellente étude réalisée par C. Fontès-Rousseau, R. Lardellier (DR Occitanie Insee) et JM Soubeyroux (Météo France). Son objectif est de mettre en regard cultures et prévisions climatiques localement, pour identifier des cultures particulièrement mises en danger par le changement climatique en France.\n\n\nEtape 3 : Evolution des cultures, lien avec le climat passé\nAprès avoir regardé vers l’avenir, il est temps de jeter un coup d’oeil dans le rétroviseur, et de regarder comment l’évolution des températures au cours des 40 dernières années a pu influencer certaines cultures en France. Nous estimerons l’évolution des dates potentielles de récolte du maïs grain dans les différents bassins de production français depuis 1980."
  },
  {
    "objectID": "app0.html#création-dun-service-postgresql",
    "href": "app0.html#création-dun-service-postgresql",
    "title": "1  Utilisation de PostgreSQL",
    "section": "1.1 Création d’un service PostgreSQL",
    "text": "1.1 Création d’un service PostgreSQL\nPour créer un service PostgreSQL sur le SSP Cloud, aller dans le catalogue de services et choisir l’onglet Databases avant de sélectionner PostgreSQL. Il est possible de modifier la configuration du service. La configuration par défaut conviendra dans la plupart des cas, mais on souhaitera parfois (et c’est le cas pour ce sujet) installer l’extension PostGIS (onglet Extensions de la configuration). A noter que lorsqu’on travaille en collaboration dans le cadre d’un projet, on préfèrera cliquer sur le bouton Partager le service pour rendre ce dernier plus facilement accessible à ses collaborateurs.\n\n\n\nPartage d’un service PostgreSQL."
  },
  {
    "objectID": "app0.html#pgadmin",
    "href": "app0.html#pgadmin",
    "title": "1  Utilisation de PostgreSQL",
    "section": "1.2 pgAdmin",
    "text": "1.2 pgAdmin\npgAdmin est une plateforme d’administration et de développement pour PostgreSQL C’est une interface graphique pour PostgreSQL. pgAdmin est disponible dans le catalogue de service du SSP Cloud (toujours dans l’onglet Databases). Une fois le service lancé, se connecter en suivant les instructions données dans le README du service. Le serveur PostgreSQL lancé au préalable devrait être automatiquement détecté par la fonction d’Autodiscovery (panneau de gauche). Il est alors possible d’accéder aux différentes bases de données disponibles sur le serveur, de les requêter (en utilisant la fonctionnalité Query Tool), etc."
  },
  {
    "objectID": "app0.html#connexion-au-service-postgresql",
    "href": "app0.html#connexion-au-service-postgresql",
    "title": "1  Utilisation de PostgreSQL",
    "section": "1.3 Connexion au service PostgreSQL",
    "text": "1.3 Connexion au service PostgreSQL\nLe serveur PostgreSQL est facilement accessible depuis n’importe quel service interactif (par exemple RStudio). Tous les langages de programmation disposent de librairies qui implémentent une interface avec PostgreSQL. En R, on peut par exemple utiliser la librairie RPostgres, basée sur la librairie DBI.\nCi-dessous, on crée l’objet conn qui va nous permettre de communiquer avec PostgreSQL. Les paramètres user, password et host sont disponibles dans le README du service PostgreSQL (le paramètre host figure dans l’URL du README et a pour valeur postgresql-xxxxxx). Ici, on choisit de stocker ces différentes valeurs dans des variables d’environnement, USER_POSTGRESQL, PASS_POSTGRESQL et HOST_POSTGRESQL, ce qui est spécifié dans le fichier ~/.Renviron. Pour éditer ce fichier, file.edit(\"~/.Renviron\") en y ajoutant les lignes USER_POSTGRESQL = \"xxx\", etc. puis relancer la session (ctrl + maj + F10).\n\nlibrary(RPostgres)\nlibrary(dplyr)\nlibrary(knitr)\nlibrary(sf)\nlibrary(janitor)\nlibrary(aws.s3)\n\n\nconn &lt;- dbConnect(Postgres(),\n                  user = Sys.getenv(\"USER_POSTGRESQL\"),\n                  password = Sys.getenv(\"PASS_POSTGRESQL\"),\n                  host = Sys.getenv(\"HOST_POSTGRESQL\"),\n                  dbname = \"defaultdb\",\n                  port = 5432,\n                  check_interrupts = TRUE)\n\nA partir de l’objet conn, il est possible d’exécuter des requêtes et de récupérer les résultats petit à petit en utilisant les fonctions dbSendQuery, dbFetch et dbClearResult. Alternativement, pour récupérer tous les résultats de la requête directement lorsqu’ils tiennent en mémoire, on peut utiliser la fonction dbGetQuery qui rassemble les trois fonctions précédentes. Des fonctions utilitaires pour l’écriture de tables sont fournies par la librairie qu’on utilise, comme dbWriteTable pour écrire une table. Ainsi, si on a des données tabulaires stockées dans un data.frame,\n\ndf &lt;- data.frame(\n  a = c(\"a\", \"b\", \"c\"),\n  b = c(1, 2, 3)\n)\n\nres &lt;- dbSendQuery(conn, \"CREATE SCHEMA IF NOT EXISTS test_schema\")\ndbWriteTable(conn, Id(schema = \"test_schema\", table = \"test_table\"), df, overwrite = TRUE)\nres &lt;- dbGetQuery(conn, \"SELECT * FROM test_schema.test_table\")\n\nres %&gt;% kable()\n\n\n\n\na\nb\n\n\n\n\na\n1\n\n\nb\n2\n\n\nc\n3"
  },
  {
    "objectID": "app0.html#utilisation-de-lextension-postgis",
    "href": "app0.html#utilisation-de-lextension-postgis",
    "title": "1  Utilisation de PostgreSQL",
    "section": "1.4 Utilisation de l’extension PostGIS",
    "text": "1.4 Utilisation de l’extension PostGIS\nPostGIS est une extension de PostgreSQL, qui active la manipulation d’informations géographiques sous forme de géométries (points, lignes, polygones). Il permet à PostgreSQL d’être un système de gestion de base de données spatial pouvant être utilisé par les systèmes d’informations géographiques.\nOn utilise la librairie sf pour gérer les données spatiales avec R. La fonction write_sf de cette librairie permet d’écrire des données dans une base de données PostGIS. Dans la suite on va illustrer comment créer une table contenant les données du RPG (décrites en détail plus tard, la documentation figure ici). Ces données sont disponibles sur MinIO au format .gpkg.\n\nparcelles &lt;- s3read_using(\n  FUN = sf::read_sf,\n  query = 'SELECT * FROM parcelles_graphiques LIMIT 10',\n  object = \"2023/sujet2/diffusion/ign/rpg/PARCELLES_GRAPHIQUES.gpkg\",\n  bucket = \"projet-funathon\",\n  opts = list(\"region\" = \"\")\n  )\n\nwrite_sf(parcelles, conn, Id(schema = \"test_schema\", table = \"test_parcelles\"), delete_layer = TRUE)\n\nOn n’a écrit que 10 observations du fichier des parcelles pour cette démontration. On peut les requêter pour vérifier que l’information géographique figure bien dans la base de données.\n\nsf &lt;- st_read(\n  conn, query = \"SELECT * FROM test_schema.test_parcelles\"\n)\n\nplot(st_geometry(sf))"
  },
  {
    "objectID": "app0.html#base-de-données-à-disposition",
    "href": "app0.html#base-de-données-à-disposition",
    "title": "1  Utilisation de PostgreSQL",
    "section": "1.5 Base de données à disposition",
    "text": "1.5 Base de données à disposition\nDans toute la suite du sujet, on propose d’utiliser une base de données déjà préconfigurée, accessible depuis n’importe où sur le SSP Cloud. Pour accéder à cette base de données de la manière décrite ci-dessus, HOST_POSTGRES doit avoir pour valeur postgresql-758156.projet-funathon. Pour récupérer le nom d’utilisateur et le mot de passe, envoyer un message à Tom Seimandi (par mail ou sur Tchap). Dans la base de données defaultdb, les schémas adminexpress, drias et rpg contiennent les données mises à disposition pour traiter le sujet. Les participants ne disposent que des droits de lecture pour ces schémas (commande SELECT). Toutefois, le schéma public est disponible pour créer des tables temporaires, n’hésitez pas à le faire !"
  },
  {
    "objectID": "app1.html#récupération-des-coordonnées-dun-point",
    "href": "app1.html#récupération-des-coordonnées-dun-point",
    "title": "2  Première manipulation du RPG",
    "section": "2.1 Récupération des coordonnées d’un point",
    "text": "2.1 Récupération des coordonnées d’un point\nCommençons par récupérer les coordonnées d’un point sur Google Maps et par les stocker dans un objet spatial grâce au package sf. Choisissez un point sur la carte et copiez ses coordonnées dans le presse-papier grâce à un clic droit. Créez ensuite deux variables lat et lon contenant la latitude et la longitude du point, ainsi qu’une variable rayon contenant le rayon souhaité pour la suite de l’analyse (en mètres).\nCréez ensuite un objet point contenant les informations spatiales du point et le rayon choisi, à partir d’un data.frame et en utilisant la fonction st_as_sf. On projettera les coordonnées dans le système Lambert 93 (EPSG:2154) grâce à la fonction st_transform. Notez que les coordonnées récupérées sur Google Maps sont des coordonnées GPS, un système de projection différent.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCode\nlibrary(tidyverse) \nlibrary(aws.s3)\nlibrary(sf)\nlibrary(RPostgres)\nlibrary(janitor)\nlibrary(kableExtra)\nlibrary(leaflet)\nlibrary(htmlwidgets)\nlibrary(RColorBrewer)\n\ncoord_gmaps &lt;- \"43.447894436406216, 1.2886163291688764\"\nlat &lt;- as.numeric(str_split(coord_gmaps, fixed(\",\"), simplify = TRUE)[,1])\nlon &lt;- as.numeric(str_split(coord_gmaps, fixed(\",\"), simplify = TRUE)[,2])\nrayon &lt;- 10000\n\n# Création d'une table sf «point» avec les coordonnées saisies\n# Transformation des coordonnées en système de proj 2154 (Lambert II) \npoint &lt;- data.frame(lon, lat, rayon) %&gt;% \n  st_as_sf(coords = c(\"lon\",\"lat\"), crs = \"EPSG:4326\") %&gt;%\n  mutate(coord_pt_gps = st_as_text(geometry)) %&gt;% \n  st_transform(\"EPSG:2154\") %&gt;% \n  st_sf() %&gt;%\n  clean_names() %&gt;% \n  rename(geom = geometry)\n\n\n\n\n\n2.1.1 Connexion au serveur PostgreSQL\nLa table des parcelles agricoles 2021 se trouve sur un serveur PostgreSQL muni de l’extension PostGIS. Connectez vous à ce serveur PostgreSQL en utilisant des variables d’environnement USER_POSTGRESQL, PASS_POSTGRESQL et HOST_POSTGRESQL bien configurées.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCode\n# Connexion à PostgreSQL\ncnx &lt;- dbConnect(Postgres(),\n                 user = Sys.getenv(\"USER_POSTGRESQL\"),\n                 password = Sys.getenv(\"PASS_POSTGRESQL\"),\n                 host = Sys.getenv(\"HOST_POSTGRESQL\"),\n                 dbname = \"defaultdb\",\n                 port = 5432,\n                 check_interrupts = TRUE)\n\n\n\n\n\n\n2.1.2 Sélection des parcelles situées autour d’un point\nOn souhaite maintenant requêter la base de données PostgreSQL pour récupérer les parcelles se situant dans un cercle du rayon choisi autour du point choisi. Pour cela, une possibilité est de passer par la création d’une table intermédiaire à partir de l’objet point défini précédemment (la fonction write_sf permet d’écrire des données spatiales dans une table PostGIS), puis d’utiliser la fonction ST_DWithin dans une requête. Stockez les résultats de la requête dans une variable parc_prox grâce à la fonction st_read.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCode\n# Optionnel, suppression de la table `point` si elle existe\nres &lt;- dbSendQuery(cnx, \"DROP TABLE IF EXISTS public.point CASCADE;\")\n\n# Ecriture de la table point dans une table PostGIS\nwrite_sf(point, cnx, Id(schema = \"public\", table = \"point\"))\n\n# Envoi de la requête de découpage du RPG autour du point sur PostGIS\nquery &lt;- \"SELECT row_number() OVER () AS row_id, p.coord_pt_gps, p.rayon, r.*  \n    FROM public.point p, rpg.parcelles r \n    WHERE ST_DWithin(p.geom, r.geom, p.rayon);\"\n\nparc_prox &lt;- st_read(cnx, query = query)\n\n\n\n\n\n\n2.1.3 Visualisation avec une carte interactive leaflet\nOn souhaite maintenant utiliser la librairie leaflet pour créer une visualisation interactive des données. On va vouloir afficher sur la carte interactive les libellés des cultures. Pour ceci, on récupère les groupes de cultures agrégés sur l’espace de stockage du SSP Cloud, avec un léger prétraitement, comme indiqué ici :\n\n# Récupération des libellés des différentes cultures\nlib_cult &lt;- s3read_using(FUN = read_csv2,\n                         object = \"2023/sujet2/diffusion/ign/rpg/REF_CULTURES_GROUPES_CULTURES_2020.csv\",\n                         col_types = cols(.default = col_character()),\n                         bucket = \"projet-funathon\",\n                         opts = list(\"region\" = \"\")) %&gt;% clean_names()\n\n\nlib_group_cult &lt;- lib_cult %&gt;% \n  select(code_groupe_culture, libelle_groupe_culture) %&gt;% \n  distinct(code_groupe_culture, .keep_all=T)\n\nlib_group_cult %&gt;% kable()\n\n\n\n\ncode_groupe_culture\nlibelle_groupe_culture\n\n\n\n\n1\nBlé tendre\n\n\n2\nMaïs grain et ensilage\n\n\n3\nOrge\n\n\n4\nAutres céréales\n\n\n5\nColza\n\n\n6\nTournesol\n\n\n7\nAutres oléagineux\n\n\n8\nProtéagineux\n\n\n9\nPlantes à fibres\n\n\n11\nGel (surfaces gelées sans production)\n\n\n14\nRiz\n\n\n15\nLégumineuses à grains\n\n\n16\nFourrage\n\n\n17\nEstives et landes\n\n\n18\nPrairies permanentes\n\n\n19\nPrairies temporaires\n\n\n20\nVergers\n\n\n21\nVignes\n\n\n22\nFruits à coque\n\n\n23\nOliviers\n\n\n24\nAutres cultures industrielles\n\n\n25\nLégumes ou fleurs\n\n\n26\nCanne à sucre\n\n\n28\nDivers\n\n\n\n\n\n\n\nOn va créer le widget grâce à la fonction leaflet, qui prend en argument une table sf. On peut ensuitea utiliser les fonctions addTiles (ajout d’un fond de carte) et addPolygons qui permet de personnaliser l’affichage des parcelles, notamment grâce à l’argument fillColor. Nous proposons une solution juste en dessous, mais n’hésitez pas à expérimenter !\n\n\n\n\n\n\nNote\n\n\n\nPour utiliser leaflet, il faut que les données spatiales soient en coordonnées GPS.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCode\n# Création d'une palette de couleurs associée au groupe de culture\nfactpal &lt;- colorFactor(\"Paired\", parc_prox$code_group)\n\n# Transformation de la projection car leaflet ne connait que le WGS 84\nparc_prox &lt;- parc_prox %&gt;% st_transform(4326)\n\n# Pour ajouter un marqueur du point\npt_mark &lt;- point %&gt;% st_transform(4326)\n\n# Ajout du libellé des cultures\nparc_prox_lib &lt;- parc_prox %&gt;% \n  left_join(lib_cult %&gt;% select(-code_groupe_culture), by = c(\"code_cultu\" = \"code_culture\")) \n\n# Création d'un label ad hoc à afficher en surbrillance au passage de la souris sur la carte\nlabels &lt;- sprintf(\"&lt;strong&gt;id_parcel : &lt;/strong&gt;%s&lt;br/&gt;\n                  &lt;strong&gt;Groupe culture : &lt;/strong&gt;%s&lt;br/&gt;\n                  &lt;strong&gt;Culture : &lt;/strong&gt;%s&lt;br/&gt;\n                  &lt;strong&gt;Surface (ha) : &lt;/strong&gt;%s&lt;br/&gt;\n                  &lt;strong&gt;Département : &lt;/strong&gt;%s&lt;br/&gt;\n                  &lt;strong&gt;Commune : &lt;/strong&gt;%s&lt;br/&gt;\",\n                  parc_prox$id_parcel,\n                  parc_prox_lib$libelle_groupe_culture,\n                  parc_prox_lib$libelle_culture,\n                  parc_prox$surf_parc,\n                  parc_prox$insee_dep,\n                  parc_prox$nom_com) %&gt;% \n  lapply(htmltools::HTML)\n\n# Création de la carte\ncarte_parc_prox_html &lt;- leaflet(parc_prox_lib) %&gt;% \n  addTiles(\"http://wxs.ign.fr/essentiels/wmts?REQUEST=GetTile&SERVICE=WMTS&VERSION=1.0.0&STYLE=normal&TILEMATRIXSET=PM&FORMAT=image/jpeg&LAYER=ORTHOIMAGERY.ORTHOPHOTOS&TILEMATRIX={z}&TILEROW={y}&TILECOL={x}\") %&gt;%\n  addPolygons(fillColor = ~factpal(code_group),\n              weight = 2,\n              opacity = 1,\n              color = \"#ffd966\",\n              dashArray = \"3\",\n              fillOpacity = 0.5,\n              highlight = highlightOptions(\n                weight = 5,\n                color = \"#A40000\",\n                dashArray = \"\",\n                fillOpacity = 0.0,\n                bringToFront = TRUE),\n              label = labels,\n              labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"15px\",\n                direction = \"auto\",\n                encoding=\"UTF-8\")) %&gt;% \n  addMarkers(data = pt_mark, ~lon, ~lat, popup = ~coord_pt_gps, label = ~coord_pt_gps)\n\n# Pour sauvegarder la carte\n# saveWidget(widget = carte_parc_prox_html, file = \"carte_parc_prox.html\")\n\ncarte_parc_prox_html\n\n\n\n\n\n\n\n\n\n\n2.1.4 Composition des parcelles agricoles récupérées\nOn souhaite calculer des statistiques sur les parcelles récupérées. Dans une table t1, inclure le nombre de parcelles par groupe de culture, ainsi que le nombre total de parcelles parmi l’échantillon issu de la requête. Faites la même chose sur la surface des parcelles, puis calculez la surface moyenne par unité de surface et groupe de culture.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCode\nt1 &lt;- parc_prox %&gt;%\n  st_drop_geometry() %&gt;%\n  count(code_group) %&gt;% \n  add_tally(n) %&gt;% \n  mutate(n_pct = round(100 * n / nn, 1)) %&gt;% \n  select(-nn) %&gt;%\n  rename(n_parcelles = n) %&gt;%\n  cbind(\n    # Surfaces\n    parc_prox %&gt;%\n      st_drop_geometry() %&gt;%\n      count(code_group, wt = surf_parc) %&gt;% \n      add_tally(n) %&gt;% \n      mutate(surf_pct = round(100 * n / nn, 1)) %&gt;%\n      select(-nn) %&gt;%  \n      rename(surf_parc_ha = n) %&gt;%\n      select(surf_parc_ha, surf_pct)\n  ) %&gt;%\n  left_join(lib_group_cult, by = c(\"code_group\" = \"code_groupe_culture\")) %&gt;% \n  select(code_group, libelle_groupe_culture, everything()) %&gt;% \n  arrange(desc(surf_parc_ha)) %&gt;% \n  adorn_totals() %&gt;% \n  mutate(taille_moy_parc = round(surf_parc_ha / n_parcelles, 1))\n\nt1  %&gt;% \n  setNames(c(\"Code\", \"Groupe de cultures\", \"Nombre de parcelles\", \"(%)\", \"Surface (ha)\", \"Surface (%)\", \"Taille moyenne (ha)\")) %&gt;% \n  kable(\n    format=\"html\",\n    caption=\"&lt;span style='font-size:medium'&gt;Groupes de cultures &lt;strong&gt;locales&lt;/strong&gt; par surfaces décroissantes&lt;/span&gt;\",\n    format.args = list(decimal.mark = \",\", big.mark = \" \"),\n    booktabs = TRUE) %&gt;%\n  kable_styling(font_size = 15) %&gt;% \n  gsub(\"font-size: initial !important;\",\n       \"font-size: 20pt !important;\",.)%&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %&gt;% \n  row_spec(nrow(t1), bold = T, color = \"white\", background = \"grey\")\n\n\n\nStructure des cultures au niveau local \n\n\nCode\nGroupe de cultures\nNombre de parcelles\n(%)\nSurface (ha)\nSurface (%)\nTaille moyenne (ha)\n\n\n\n\n1\nBlé tendre\n631\n10,9\n3 044,52\n17,6\n4,8\n\n\n2\nMaïs grain et ensilage\n368\n6,4\n2 922,39\n16,9\n7,9\n\n\n4\nAutres céréales\n404\n7,0\n1 826,24\n10,6\n4,5\n\n\n11\nGel (surfaces gelées sans production)\n1 437\n24,9\n1 494,91\n8,7\n1,0\n\n\n6\nTournesol\n308\n5,3\n1 430,40\n8,3\n4,6\n\n\n18\nPrairies permanentes\n573\n9,9\n1 260,24\n7,3\n2,2\n\n\n7\nAutres oléagineux\n184\n3,2\n1 237,37\n7,2\n6,7\n\n\n3\nOrge\n214\n3,7\n947,61\n5,5\n4,4\n\n\n16\nFourrage\n234\n4,1\n804,31\n4,7\n3,4\n\n\n19\nPrairies temporaires\n302\n5,2\n802,74\n4,6\n2,7\n\n\n8\nProtéagineux\n116\n2,0\n538,13\n3,1\n4,6\n\n\n5\nColza\n106\n1,8\n468,59\n2,7\n4,4\n\n\n28\nDivers\n754\n13,1\n184,22\n1,1\n0,2\n\n\n15\nLégumineuses à grains\n34\n0,6\n147,28\n0,9\n4,3\n\n\n25\nLégumes ou fleurs\n38\n0,7\n46,95\n0,3\n1,2\n\n\n21\nVignes\n21\n0,4\n37,31\n0,2\n1,8\n\n\n17\nEstives et landes\n16\n0,3\n33,19\n0,2\n2,1\n\n\n24\nAutres cultures industrielles\n23\n0,4\n32,70\n0,2\n1,4\n\n\n20\nVergers\n7\n0,1\n4,76\n0,0\n0,7\n\n\nTotal\n-\n5 770\n100,0\n17 263,86\n100,1\n3,0\n\n\n\n\n\n\n\n\n\n\n\n2.1.5 Comparaison avec la répartition des cultures au niveau départemental et national\nOn va vouloir comparer la composition des parcelles à proximité du point choisi avec la composition au niveaux départemental et national. Pour ce faire, commencer par faire une jointure spatiale sur PostGIS pour récupérer le département du point. Les géométries des départements se récupèrent avec la commande suivante :\n\n# Couche département pour récupérer le département du point\ndep &lt;- s3read_using(\n    FUN = sf::read_sf,\n    layer = \"departement\",\n    object = \"2023/sujet2/diffusion/ign/adminexpress_cog_simpl_000_2023.gpkg\",\n    bucket = \"projet-funathon\",\n    opts = list(\"region\" = \"\")) %&gt;% \n  st_transform(2154)\n\nPour faire la jointure spatiale, on pourra utiliser la fonction st_join.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCode\n# Jointure spatiale\ndf &lt;- point %&gt;% st_join(dep) %&gt;% st_drop_geometry() %&gt;% select(insee_dep)\ndep_pt &lt;- df[1,1]\n\n\n\n\nPour ne pas avoir à refaire de gros calculs sur la table RPG, les statistiques départementales et nationales sont disponibles directement grâce aux commandes suivantes :\n\n# Récupération des statistiques départementales\nstat_dep_pt &lt;- s3read_using(\n  FUN = readr::read_rds,\n  object = \"2023/sujet2/diffusion/resultats/stat_group_cult_by_dep.rds\",\n  bucket = \"projet-funathon\",\n  opts = list(\"region\" = \"\"))\n\n# Récupération des statistiques nationales\nstat_fm &lt;- s3read_using(\n  FUN = readr::read_csv,\n  object = \"2023/sujet2/diffusion/resultats/stat_group_cult_fm.csv\",\n  col_types = cols(code_group = col_character()),\n  bucket = \"projet-funathon\",\n  opts = list(\"region\" = \"\")) %&gt;% \n  select(code_group, libelle_groupe_culture, pct_surf) %&gt;% \n  rename(pct_surf_fm = pct_surf)\n\nSélectionnez les statistiques du département concerné et appariez statistiques de surfaces locales, départementales et nationales par groupe de culture dans un même data.frame à afficher, comme ci-dessous.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCode\n# Calcul des % surfaces autour du point\nstat_pt &lt;- parc_prox %&gt;%\n  st_drop_geometry() %&gt;% \n  count(code_group, wt = surf_parc) %&gt;%\n  add_tally(n) %&gt;% \n  mutate(pct_surf_local = round(100 * n / nn, 1)) %&gt;%\n  select(code_group, pct_surf_local) \n\n# Récupération des statistiques du département concerné\nstat_dep_pt &lt;- stat_dep_pt %&gt;% \n  filter(insee_dep %in% dep_pt) %&gt;% \n  select(insee_dep, code_group, libelle_groupe_culture, pct_surf) %&gt;% \n  rename(pct_surf_dep = pct_surf)\n\n# Appariement des statistiques locale, départementale et nationale\nstat_compar &lt;- stat_fm %&gt;% \n  left_join(stat_dep_pt %&gt;% select(code_group, pct_surf_dep), by = \"code_group\") %&gt;% \n  left_join(stat_pt , by = \"code_group\") %&gt;% \n  select(libelle_groupe_culture, pct_surf_local, pct_surf_dep, pct_surf_fm) %&gt;% \n  arrange(desc(pct_surf_local)) %&gt;%\n  adorn_totals() \n\nstat_compar %&gt;% \n  setNames(c(\"Groupe de cultures\",\"Surf. locales (%)\", \"Surf. départ. (%)\",\"Surf. France m. (%)\")) %&gt;%\n  kable(\n    format=\"html\",\n    caption=\"&lt;span style='font-size:medium'&gt;Comparaison des surfaces locales, départementales et nationales&lt;/span&gt;\",\n    format.args = list(decimal.mark = \",\", big.mark = \" \"),\n    booktabs = TRUE) %&gt;%\n  kable_styling(font_size = 15) %&gt;% \n  gsub(\"font-size: initial !important;\",\n       \"font-size: 20pt !important;\",.)%&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %&gt;% \n  row_spec(nrow(stat_compar), bold = T, color = \"white\", background = \"grey\")\n\n\n\nStructure des cultures \n\n\nGroupe de cultures\nSurf. locales (%)\nSurf. départ. (%)\nSurf. France m. (%)\n\n\n\n\nBlé tendre\n17,6\n14,3\n17,7\n\n\nMaïs grain et ensilage\n16,9\n8,6\n10,0\n\n\nAutres céréales\n10,6\n12,4\n3,9\n\n\nGel (surfaces gelées sans production)\n8,7\n4,4\n1,6\n\n\nTournesol\n8,3\n12,6\n2,5\n\n\nPrairies permanentes\n7,3\n17,9\n27,7\n\n\nAutres oléagineux\n7,2\n3,1\n0,7\n\n\nOrge\n5,5\n3,5\n6,2\n\n\nFourrage\n4,7\n5,9\n3,7\n\n\nPrairies temporaires\n4,6\n4,2\n5,3\n\n\nProtéagineux\n3,1\n1,8\n1,2\n\n\nColza\n2,7\n1,8\n3,5\n\n\nDivers\n1,1\n1,3\n1,3\n\n\nLégumineuses à grains\n0,9\n0,3\n0,2\n\n\nLégumes ou fleurs\n0,3\n0,3\n1,5\n\n\nEstives et landes\n0,2\n6,9\n8,1\n\n\nVignes\n0,2\n0,4\n2,2\n\n\nAutres cultures industrielles\n0,2\n0,1\n1,8\n\n\nVergers\n0,0\n0,1\n0,4\n\n\nPlantes à fibres\nNA\n0,0\n0,4\n\n\nRiz\nNA\nNA\n0,0\n\n\nFruits à coque\nNA\n0,0\n0,2\n\n\nOliviers\nNA\n0,0\n0,0\n\n\nTotal\n100,1\n99,9\n100,1\n\n\n\n\n\n\n\n\n\n\n\n2.1.6 Graphique de comparaison des cultures au niveau local, départemental et national\nOn souhaite faire un graphique avec ggplot2 pour visualiser la comparaison établie ci-dessus. Utilisez la fonction geom_col pour obtenir le graphique affiché ci-dessous.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCode\n# Sélection des 10 groupes de cultures les plus répandus au niveau local \ntab &lt;- stat_compar %&gt;%\n  filter(libelle_groupe_culture != \"Total\") %&gt;%\n  slice_head(n=10) %&gt;% \n  rename(local = pct_surf_local, departement = pct_surf_dep, france = pct_surf_fm)\n\n# Transposition de la table pour rassembler toutes les valeurs dans une seule variable value\ntab_piv &lt;- tab %&gt;% pivot_longer(!libelle_groupe_culture) %&gt;% rename(secteur = name) \n\n# Valeurs manquantes à\ntab_piv[is.na(tab_piv)] &lt;- 0\n\n# On réordonne les secteurs dans le \"bon\" ordre, avec factor\ntab_piv$secteur &lt;- factor(\n  tab_piv$secteur,\n  levels = c(\"france\", \"departement\", \"local\"))\ntab_piv &lt;- tab_piv %&gt;% arrange(desc(secteur), desc(value))\n\n# On réordonne les cultures par surface décroissante au niveau local, avec factor\nx &lt;- tab_piv %&gt;% filter(secteur == \"local\") %&gt;% arrange(value) %&gt;% select(libelle_groupe_culture)\ny &lt;- pull(x, libelle_groupe_culture)\n\ntab_piv$libelle_groupe_culture &lt;- factor(tab_piv$libelle_groupe_culture, levels = y)\n\n# Visualisation avec `geom_col`\np &lt;- ggplot(tab_piv, aes(x = libelle_groupe_culture,\n                         y = value, \n                         fill = factor(\n                           secteur,\n                           levels = c(\"france\", \"departement\", \"local\")))) + \n  geom_col(position = \"dodge\") +\n  labs(title = \"Surfaces comparées des 10\\nprincipales cultures locales, en %\", x=\"Culture\", y = \"%\", fill = \"Secteur\") +\n  theme_classic()\n\n# Flip du graphique pour avoir des barres horizontales  \np + coord_flip()\n\n\n\n\n\n\n\n\n\n2.1.7 Graphique par secteur\nLa fonction facet_wrap permet d’afficher plusieurs graphiques côte-à-côte. En utilisant cette fonction, réalisez le graphique affiché ci-dessous.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCode\n# Visualisation avec `geom_col` et `facet_wrap`   \nggplot(tab_piv, \n       aes(x = libelle_groupe_culture,\n           y = value)) + \n  geom_col(fill = \"lightblue\", colour = \"black\", position = \"dodge\") +\n  labs(title = \"Surface par culture\", x= \"Culture\", y = \"%\", fill = \"Secteur\") +\n  geom_text(aes(label = value), hjust = -0.3, size = 8/.pt, colour = \"black\") +\n  theme_classic() + coord_flip() + \n  facet_wrap(~secteur, nrow=3, scales='free')"
  },
  {
    "objectID": "app1.html#création-dun-dashboard-de-visualisation",
    "href": "app1.html#création-dun-dashboard-de-visualisation",
    "title": "2  Première manipulation du RPG",
    "section": "2.2 Création d’un dashboard de visualisation",
    "text": "2.2 Création d’un dashboard de visualisation\nOn souhaiterait intégrer les analyses faites ci-dessus à un tableau de bord qui offrirait des visualisations interactives. Une solution est d’utiliser shiny, une librairie qui permet la création de telles applications avec R notamment.\nUne application shiny simple a deux composants principaux :\n\nUn objet d’interface utilisateur (UI) qui contrôle la disposition et l’apparence du tableau de bord ;\nUne fonction serveur qui contient les instructions nécessaires au fonctionnement de l’application.\n\nLorsque ces deux composants sont définis, l’application est lancée à l’aide d’une simple instruction runApp. Ici, on aimerait bien aller vers une première version de tableau de bord, qui afficherait au départ une carte interactive et laisserait aussi à l’utilisateur de choisir un rayon. Une fois ce rayon choisi et un point sélectionné grâce à un clic sur la carte, on souhaiterait (comme affiché ci-dessous) :\n\nAfficher sur la carte les parcelles se situant à une distance inférieure au rayon choisi du point spécifié ;\nAfficher des statistiques sur les parcelles en questions.\n\n Ainsi notre UI sera un objet fluidPage composé de trois éléments, et dans la fonction de serveur il y aura deux évènements distincts à observer. Pour développer l’application, créez un répertoire my_app et à l’intérieur 3 fichiers, un fichier ui.R, un fichier server.R et un fichier utils.R (dans lequel se trouveront les fonctions utilitaires)."
  },
  {
    "objectID": "app1.html#ui",
    "href": "app1.html#ui",
    "title": "2  Première manipulation du RPG",
    "section": "2.3 UI",
    "text": "2.3 UI\nLe fichier UI aura la forme suivante :\n\nlibrary(shiny)\n\n# Define UI\nui &lt;- fluidPage(\n  ...\n)\n\nA l’intérieur de la fonction fluidPage et grâce à la documentation de Shiny, ajoutez les 3 éléments qui constitueront le tableau de bord : un output de type “carte leaflet”, un champ d’input numérique, et un output de type “table”.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCode\nlibrary(shiny)\n\n# Define UI\nui &lt;- fluidPage(\n  leafletOutput(\"map\", height = 800),\n  numericInput(\"buffer_radius\", \"Rayon (en km) :\", value = 5),\n  tableOutput(\"table\")\n)"
  },
  {
    "objectID": "app1.html#serveur",
    "href": "app1.html#serveur",
    "title": "2  Première manipulation du RPG",
    "section": "2.4 Serveur",
    "text": "2.4 Serveur\nLe code de la fonction serveur figure ci-dessous dans son intégralité, et l’objectif de cette partie va être d’implémenter dans utils.R les différentes fonctions appelées dans le code :\n\nconnect_to_db : une fonction qui renvoie une connexion à la base de données ;\nquery_db : une fonction qui interroge la base de données pour récupérer les parcelles se situant à l’intérieur d’un cercle de rayon radius d’un point défini par une latitude et une longitude ;\nplot_surroundings : une fonction qui prend en entrée la sortie de la fonction query_db et une carte leaflet et qui ajoute une couche comportant les polygones des parcelles concernées ;\ncompute_stats : une fonction qui prend en entrée la sortie de la fonction query_db et renvoie des statistiques sur les parcelles concernées.\n\n\nlibrary(shiny)\nlibrary(leaflet)\n\n\n# Définition du serveur\nserver &lt;- function(input, output) {\n  \n  # Rendre la carte\n  output$map &lt;- renderLeaflet({\n    leaflet() %&gt;%\n      addTiles(\"http://wxs.ign.fr/essentiels/wmts?REQUEST=GetTile&SERVICE=WMTS&VERSION=1.0.0&STYLE=normal&TILEMATRIXSET=PM&FORMAT=image/jpeg&LAYER=ORTHOIMAGERY.ORTHOPHOTOS&TILEMATRIX={z}&TILEROW={y}&TILECOL={x}\") %&gt;%\n      setView(lng = -1.4932577154775046, lat = 46.46946179131805, zoom = 12)\n  })\n  \n  # Connexion à la base de données\n  cnx &lt;- connect_to_db()\n  \n  # Initialisation d'une \"reactive value\" pour le point sélectionné\n  selectedPoint &lt;- reactiveValues(lat = NULL, lng = NULL)\n  \n  # Gestion de l'évènement \"clic\"\n  observeEvent(input$map_click, {\n    \n    clickData &lt;- input$map_click\n    if (!is.null(clickData)) {\n      # Stockage des coordonnées du point\n      selectedPoint$lat &lt;- clickData$lat\n      selectedPoint$lng &lt;- clickData$lng\n      \n      buffer_radius &lt;- input$buffer_radius\n      sf &lt;- query_db(cnx, selectedPoint$lat, selectedPoint$lng, buffer_radius)\n\n      # Mise à jour de la carte\n      leafletProxy(\"map\") %&gt;%\n        clearMarkers() %&gt;%\n        clearShapes() %&gt;%\n        addMarkers(lng = selectedPoint$lng, lat = selectedPoint$lat) %&gt;%\n        plot_surroundings(sf)\n      \n      # Calculs sur les données de parcelles\n      df &lt;- compute_stats(sf)\n      \n      # Update de la table affichée\n      output$table &lt;- renderTable({\n        df\n      })\n    }\n  })\n  \n  observeEvent(input$buffer_radius, {\n    # Vérification qu'un point a été sélectionné\n    if (!is.null(selectedPoint$lat) && !is.null(selectedPoint$lng)) {\n      # Requête avec le nouveau rayon\n      buffer_radius &lt;- input$buffer_radius\n      sf &lt;- query_db(cnx, selectedPoint$lat, selectedPoint$lng, buffer_radius)\n      \n      # Mise à jour de la carte\n      leafletProxy(\"map\") %&gt;%\n        clearShapes() %&gt;%\n        plot_surroundings(sf)\n      \n      # Calculs sur les données de parcelles\n      df &lt;- compute_stats(sf)\n      \n      # Update de la table affichée\n      output$table &lt;- renderTable({\n        df\n      })\n    }\n  })\n}\n\nProposer une implémentation des fonctions connect_to_db, query_db et compute_stats décrites ci-dessus et utilisées dans la fonction “serveur”.\n\n2.4.1 connect_to_db\nLa fonction connect_to_db renvoie une connexion à la base de données PostgreSQL, comme vu précédemment. Les identifiants (user et password sont respectivement stockés dans les variables d’environnement USER_POSTGRESQL et PASS_POSTGRESQL.)\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCode\n#' Connection au serveur PostgreSQL. Le mot de passe doit être stocké dans la\n#' variable d'environnement PASS_POSTGRESQL.\n#' \n#' @returns Connexion au serveur.\nconnect_to_db &lt;- function() {\n  # Connection à PostgreSQL\n  cnx &lt;- dbConnect(Postgres(),\n                   user = Sys.getenv(\"USER_POSTGRESQL\"),\n                   password = Sys.getenv(\"PASS_POSTGRESQL\"),\n                   host = \"postgresql-758156.projet-funathon\",\n                   dbname = \"defaultdb\",\n                   port = 5432,\n                   check_interrupts = TRUE)\n  \n  return(cnx)\n}\n\n\n\n\n\n\n2.4.2 query_db\nOn souhaite implémenter la fonction suivante :\n\n#' Requête la table `parcelles` pour récupérer les parcelles qui se situent\n#' dans un certain rayon autour d'un point repéré par une latitude et \n#' une longitude.\n#' \n#' @param cnx Connexion à PostgreSQL.\n#' @param lat Latitude.\n#' @param lng Longitude.\n#' @param radius Rayon.\n#' @returns Objet `sf` avec les données des parcelles concernées.\nquery_db &lt;- function(cnx, lat, lng, radius) {\n  ...\n}\n\nOn pourra notamment utiliser plusieurs fonctions PostGIS :\n\nST_MakePoint qui permet de créer une géométrie POINT;\nST_SetSRID qui permet de définir le système de coordonnées pour une géométrie;\nST_Buffer qui calcule un POLYGON ou un MULTIPOLYGON qui représente tous les points dont la distance par rapport à une géométrie/géographie est inférieure ou égale à une distance donnée;\nST_Intersects qui compare deux géométries et renvoie true si elles ont une intersection non-nulle;\n\nainsi que des fonction de la librairie sf.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCode\n#' Requête la table `parcelles` pour récupérer les parcelles qui se situent\n#' dans un certain rayon autour d'un point repéré par une latitude et \n#' une longitude.\n#' \n#' @param cnx Connexion à PostgreSQL.\n#' @param lat Latitude.\n#' @param lng Longitude.\n#' @param radius Rayon.\n#' @returns Objet `sf` avec les données des parcelles concernées.\nquery_db &lt;- function(cnx, lat, lng, radius) {\n  # Les données spatiales sur PostgreSQL sont stockées en Lambert 93.\n  # Pour faire le join on veut donc projeter les coordonnées `lat`` et `lng`\n  postgis_crs &lt;- \"EPSG:2154\"\n  coordinates &lt;- data.frame(lng = c(lng), lat = c(lat)) %&gt;%\n    st_as_sf(coords = c(\"lng\", \"lat\"), remove = TRUE) %&gt;%\n    st_set_crs(\"EPSG:4326\") %&gt;%\n    st_transform(postgis_crs)\n  \n  # Requête PostgreSQL\n  query &lt;- sprintf(\n    \"SELECT * FROM rpg.parcelles WHERE ST_Intersects(geom, ST_Buffer(ST_SetSRID(ST_MakePoint(%f, %f), 2154), %.0f));\",\n    st_coordinates(coordinates)[1],\n    st_coordinates(coordinates)[2],\n    radius*1000)\n  \n  # Récupération des résultats\n  sf &lt;- st_read(\n    cnx,\n    query = query\n  )\n  \n  return(sf)\n}\n\n\n\n\n\n\n2.4.3 compute_stats\nOn souhaite implémenter la fonction suivante :\n\n#' Crée la table à afficher sur l'application grâce à des calculs sur les\n#' données requêtées depuis PostgreSQL.\n#' \n#' @param sf Données spatiales.\n#' @returns data.frame à afficher.\ncompute_stats &lt;- function(sf) {\n  ...\n}\n\nqui calcule sur une table spatiale renvoyée par la fonction query_db (ensemble des parcelles se situant autour d’un point donné) les statistiques suivantes par groupe de culture agregé :\n\nNombre de parcelles;\nPourcentage des parcelles parmi toutes les parcelles;\nSurface des parcelles;\nSurface des parcelles rapportée à la surface de toutes les parcelles;\nSurface moyenne d’une parcelle.\n\nOn récupère les groupes de cultures agrégés sur l’espace de stockage du SSP Cloud et avec un léger prétraitement, comme précédemment :\n\n# Récupération des libellés des différentes cultures\nlib_cult &lt;- s3read_using(FUN = read_csv2,\n                         object = \"2023/sujet2/diffusion/ign/rpg/REF_CULTURES_GROUPES_CULTURES_2020.csv\",\n                         col_types = cols(.default = col_character()),\n                         bucket = \"projet-funathon\",\n                         opts = list(\"region\" = \"\")) %&gt;% clean_names()\n\n\nlib_group_cult &lt;- lib_cult %&gt;% \n  select(code_groupe_culture, libelle_groupe_culture) %&gt;% \n  distinct(code_groupe_culture, .keep_all=T)\n\nlib_group_cult %&gt;% kable()\n\n\n\n\ncode_groupe_culture\nlibelle_groupe_culture\n\n\n\n\n1\nBlé tendre\n\n\n2\nMaïs grain et ensilage\n\n\n3\nOrge\n\n\n4\nAutres céréales\n\n\n5\nColza\n\n\n6\nTournesol\n\n\n7\nAutres oléagineux\n\n\n8\nProtéagineux\n\n\n9\nPlantes à fibres\n\n\n11\nGel (surfaces gelées sans production)\n\n\n14\nRiz\n\n\n15\nLégumineuses à grains\n\n\n16\nFourrage\n\n\n17\nEstives et landes\n\n\n18\nPrairies permanentes\n\n\n19\nPrairies temporaires\n\n\n20\nVergers\n\n\n21\nVignes\n\n\n22\nFruits à coque\n\n\n23\nOliviers\n\n\n24\nAutres cultures industrielles\n\n\n25\nLégumes ou fleurs\n\n\n26\nCanne à sucre\n\n\n28\nDivers\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCode\n#' Crée la table à afficher sur l'application grâce à des calculs sur les\n#' données requêtées depuis PostgreSQL.\n#' \n#' @param sf Données spatiales.\n#' @returns data.frame à afficher.\ncompute_stats &lt;- function(sf) {\n  df &lt;- sf %&gt;% \n    st_drop_geometry() %&gt;%\n    count(code_group, name = \"parcelles_grp\") %&gt;%\n    add_tally(parcelles_grp, name = \"parcelles_tot\") %&gt;%\n    mutate(pct_parcelles = round(100*parcelles_grp/parcelles_tot, 1)) %&gt;%\n    select(-parcelles_tot) %&gt;%\n    cbind(\n      # Comptage des surfaces\n      sf %&gt;% \n        st_drop_geometry() %&gt;%\n        count(code_group, wt = surf_parc, name = \"surface_grp\") %&gt;% \n        add_tally(surface_grp, name = \"surface_tot\") %&gt;% \n        mutate(surface_pct = round(100*surface_grp/surface_tot, 1)) %&gt;%\n        select(-surface_tot) %&gt;%\n        select(surface_grp, surface_pct)\n      ) %&gt;% \n    left_join(lib_group_cult, by = c(\"code_group\" = \"code_groupe_culture\")) %&gt;% \n    select(code_group, libelle_groupe_culture, everything()) %&gt;% \n    arrange(desc(surface_grp)) %&gt;% \n    adorn_totals() %&gt;% \n    mutate(mean_surface = round(surface_grp/parcelles_grp, 1))\n\n  return(\n    df %&gt;%\n      select(-code_group) %&gt;%\n      setNames(\n        c(\n          \"Groupe de cultures\",\n          \"Nombre de parcelles\",\n          \"Pourcentage de parcelles\",\n          \"Surface (ha)\",\n          \"Surface (%)\",\n          \"Surface moyenne d'une parcelle (ha)\"))\n  )\n}\n\n\n\n\n\n\n2.4.4 plot_surroundings\nLa fonction plot_surroundings prend en entrée une carte leaflet ainsi qu’un objet sf récupéré grâce à query_db et renvoie une carte où on a rajouté une couche avec les polygones correspondant aux parcelles. Elle est donné ci-dessous. Essayez de comprendre à quoi correspondent les différents arguments de la fonction addPolygons.\n\n# Création d'une palette de couleurs associée au groupe de culture\npal &lt;- brewer.pal(12, \"Paired\")\npal &lt;- colorRampPalette(pal)(24)\nfactpal &lt;- colorFactor(pal, lib_group_cult$code_groupe_culture)\n\n#' Rajoute les données d'un objet `sf` sous forme de polygones à une\n#' carte `leaflet`.\n#' \n#' @param leaflet_proxy Carte.\n#' @param sf Données spatiales.\n#' @returns Carte enrichie.\nplot_surroundings &lt;- function(leaflet_proxy, sf) {\n  # Transformation de la projection (WGS 84)\n  sf &lt;- sf %&gt;% st_transform(4326)\n  \n  # Ajout des libellés des cultures\n  sf &lt;- sf %&gt;% \n    left_join(lib_cult %&gt;% select(-code_groupe_culture), by = c(\"code_cultu\" = \"code_culture\")) \n  \n  # Création des labels à afficher au passage de la souris sur la carte.\n  labels &lt;- sprintf(\"&lt;strong&gt;Identifiant de la parcelle : &lt;/strong&gt;%s&lt;br/&gt;\n                    &lt;strong&gt;Groupe culture : &lt;/strong&gt;%s&lt;br/&gt;\n                    &lt;strong&gt;Culture : &lt;/strong&gt;%s&lt;br/&gt;\n                    &lt;strong&gt;Surface (ha) : &lt;/strong&gt;%s&lt;br/&gt;\n                    &lt;strong&gt;Département : &lt;/strong&gt;%s&lt;br/&gt;\n                    &lt;strong&gt;Commune : &lt;/strong&gt;%s&lt;br/&gt;\",\n                    sf$id_parcel,\n                    sf$libelle_groupe_culture,\n                    sf$libelle_culture,\n                    sf$surf_parc,\n                    sf$insee_dep,\n                    sf$nom_com) %&gt;%\n    lapply(htmltools::HTML)\n\n  return(\n    leaflet_proxy %&gt;%\n    addPolygons(\n      data = sf,\n      fillColor = ~factpal(code_group),\n      weight = 2,\n      opacity = 1,\n      color = \"#ffd966\",\n      dashArray = \"3\",\n      fillOpacity = 0.5,\n      highlight = highlightOptions(\n        weight = 5,\n        color = \"#A40000\",\n        dashArray = \"\",\n        fillOpacity = 0.0,\n        bringToFront = TRUE),\n      label = labels,\n      labelOptions = labelOptions(\n        style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n        textsize = \"15px\",\n        direction = \"auto\",\n        encoding=\"UTF-8\"))\n  )\n}"
  },
  {
    "objectID": "app1.html#lancement-de-lapplication",
    "href": "app1.html#lancement-de-lapplication",
    "title": "2  Première manipulation du RPG",
    "section": "2.5 Lancement de l’application",
    "text": "2.5 Lancement de l’application\nL’application RShiny se lance localement grâce à la commande shiny::runApp(\"my-app\"). Vérifiez que tout fonctionne bien ! Une application fonctionnelle se trouve dans le répertoire app si besoin."
  },
  {
    "objectID": "app2.html#données",
    "href": "app2.html#données",
    "title": "3  Cultures et prévisions climatiques",
    "section": "3.1 Données",
    "text": "3.1 Données\n\nLe RPG recense les parcelles déclarées à la PAC par les agriculteurs, leurs informations graphiques et leur culture principale. Ces données sont mises à disposition dans une base de données PostgreSQL.\nLe projet Drias a pour vocation de mettre à disposition des projections climatiques réalisées dans les laboratoires français de modélisation du climat (IPSL, CERFACS, CNRM). En particulier, nous disposons de projections locales du modèle CNRM-CM5 / ALADIN63 / correction ADAMONT. Ces données sont aussi mises à disposition sur PostgreSQL."
  },
  {
    "objectID": "app2.html#visualisations",
    "href": "app2.html#visualisations",
    "title": "3  Cultures et prévisions climatiques",
    "section": "3.2 Visualisations",
    "text": "3.2 Visualisations\nOn initialise une nouvelle fois la connexion à PostgreSQL comme expliqué à la fin de l’application 0.\n\nlibrary(RPostgres)\nlibrary(dplyr)\nlibrary(aws.s3)\nlibrary(ggplot2)\nlibrary(raster)\nlibrary(sf)\nlibrary(janitor)\nlibrary(knitr)\n\n# Pour avoir les noms de dates en français\ninvisible(Sys.setlocale(\"LC_ALL\", \"fr_FR.UTF-8\"))\n\noptions(knitr.kable.NA = \"\")\n\ncnx &lt;- dbConnect(Postgres(),\n                 user = Sys.getenv(\"USER_POSTGRESQL\"),\n                 password = Sys.getenv(\"PASS_POSTGRESQL\"),\n                 host = Sys.getenv(\"HOST_POSTGRESQL\"),\n                 dbname = \"defaultdb\",\n                 port = 5432,\n                 check_interrupts = TRUE)\n\nOn souhaite tout d’abord visualiser les données DRIAS. On peut passer par les données sauvegardées au format raster qui sont stockées dans l’espace de stockage du SSP Cloud. Ces données correspondent à des prévisions à horizon proche (2021-2050) dans un scénario sans réduction des gaz à effet de serre, la période de référence étant 1976-2005. Le code ci-dessous permet de récupérer les données.\n\ndrias_raster &lt;- s3read_using(\n  function(f) readAll(brick(f)),\n  object = \"2023/sujet2/diffusion/resultats/drias.tif\",\n  bucket = \"projet-funathon\",\n  opts = list(\"region\" = \"\"))\n\ndrias_df &lt;- as.data.frame(drias_raster, xy = TRUE) %&gt;% tidyr::drop_na()\ncolnames(drias_df) &lt;- c(\n  \"x\",\n  \"y\",\n  \"NORRRA\",\n  \"NORSTM6\",\n  \"NORSTM0\",\n  \"NORSDA\",\n  \"NORDATEVEG\",\n  \"NORDATEDG\",\n  \"NORDATEPG\",\n  \"ARRA\",\n  \"ASTM6\",\n  \"ASTM0\",\n  \"ASDA\",\n  \"ADATEVEG\",\n  \"ADATEDG\",\n  \"ADATEPG\",\n  \"ALTI\"\n)\n\ndrias_df %&gt;% head(10) %&gt;% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx\ny\nNORRRA\nNORSTM6\nNORSTM0\nNORSDA\nNORDATEVEG\nNORDATEDG\nNORDATEPG\nARRA\nASTM6\nASTM0\nASDA\nADATEVEG\nADATEDG\nADATEPG\nALTI\n\n\n\n\n633222.7\n7102519\n456.2780\n1922.019\n3166.208\n1.970000\n37.00000\n246.0152\n155.0000\n39.49532\n186.3507\n242.3591\n0.1700000\n-6.000000\n-13.03036\n9.924110\n2.000000\n\n\n641222.7\n7102519\n443.9634\n1991.784\n3237.846\n1.703987\n37.00000\n231.2215\n156.9705\n35.80390\n182.8417\n240.3598\n0.1305907\n-6.000000\n-15.95570\n1.132903\n2.000000\n\n\n649222.7\n7102519\n443.9969\n1995.343\n3242.508\n1.867559\n37.00000\n227.0574\n157.9856\n31.55116\n181.4101\n241.3846\n0.3665546\n-6.000000\n-21.91386\n1.985644\n1.014356\n\n\n657222.7\n7102519\n436.6389\n2002.257\n3246.031\n2.067211\n37.00000\n232.9163\n158.0000\n24.69242\n188.7246\n250.9371\n0.4686055\n-6.000000\n-18.05578\n6.930274\n2.521252\n\n\n665222.7\n7102519\n435.9542\n2000.975\n3246.324\n2.058347\n37.00000\n230.7862\n158.4427\n24.02779\n186.6543\n248.8595\n0.4583470\n-6.000000\n-17.55724\n3.799755\n2.349262\n\n\n673222.7\n7102519\n435.9155\n2000.556\n3245.985\n2.050125\n37.00000\n230.5039\n158.4992\n23.95599\n186.3690\n248.5641\n0.4501251\n-6.000000\n-17.50078\n3.503910\n2.497654\n\n\n609222.7\n7094519\n479.2000\n1851.100\n3046.770\n1.700000\n39.00000\n242.0000\n152.0000\n52.62000\n193.7900\n246.7000\n0.0300000\n-8.000000\n-21.00000\n6.000000\n66.000000\n\n\n617222.7\n7094519\n468.7802\n1908.548\n3134.198\n1.729771\n38.00763\n244.9771\n152.9924\n51.21084\n195.0900\n248.3969\n-0.0692365\n-7.007635\n-17.03054\n6.000000\n20.351189\n\n\n625222.7\n7094519\n461.3004\n1925.008\n3168.732\n1.968268\n37.00722\n246.9856\n154.9856\n45.71983\n190.3150\n242.9796\n0.1682681\n-6.007217\n-15.01443\n5.007217\n1.642246\n\n\n633222.7\n7094519\n456.2343\n1922.001\n3166.199\n1.970000\n37.00000\n246.0068\n155.0000\n39.44270\n186.3171\n242.3540\n0.1700000\n-6.000000\n-13.01360\n9.966008\n1.996718\n\n\n\n\n\nLes variables disponibles dans les données DRIAS sont systématiquement calculées sur la période 2021-2050 (préfixe NOR), et en écart avec la période de référence (préfixe A) :\n\nRRA : cumul de précipitations d’avril à octobre (mm)\nSTM6 : somme de température base 6°C d’avril à octobre (°C)\nSTM0 : somme de température base 0°C d’octobre (année-1) à juillet (année) (°C)\nSDA : nombre de jours d’été d’avril à juin (jour(s))\nDATEVEG : date de reprise de végétation en jour julien (date)\nDATEDG : Date de dernière gelée avec 1er juillet comme référence (date)\nDATEPG : Date de première gelée avec 1er juillet comme référence (date)\n\nOn souhaite visualiser la variable ARRA, qui correspond à la huitième couche du raster et correspond à l’écart de cumul de précipitations d’avril à octobre en mm. Pour faire cela, on pourra récupérer spécifiquement la couche désirée lors de l’utilisation de la fonction raster::raster. Pour la visualisation, on pourra utiliser raster::plot.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCode\n# Bande ARRA\ndrias_raster_arra &lt;- s3read_using(\n  function(f) readAll(raster(f, band = 8)),\n  object = \"2023/sujet2/diffusion/resultats/drias.tif\",\n  bucket = \"projet-funathon\",\n  opts = list(\"region\" = \"\"))\n\n# Avec palette custom\npalette &lt;- c(\"#1457ff\", \"#3c9aff\", \"#6dc4ff\", \"#a8e1ff\", \"#dff1fb\", \"#f8e9eb\", \"#fca8ab\", \"#f9575d\", \"#f2060b\", \"#a20102\")\nbreaks &lt;- c(-200, -160, -120, -80, -40, -0, 40, 80, 120, 160, 200)\n\nraster::plot(x = drias_raster_arra,\n             col = rev(palette),\n             breaks = breaks,\n             main = \"Ecart de cumul de précipitations d'avril à octobre (mm)\\nentre 2021-2050 et 1976-2005\")\n\n\n\n\n\n\n\nSur la période 2021-2050, les précipitations vont augmenter presque partout, sauf dans le Sud-Ouest de la France."
  },
  {
    "objectID": "app2.html#requêtes-postgresql",
    "href": "app2.html#requêtes-postgresql",
    "title": "3  Cultures et prévisions climatiques",
    "section": "3.3 Requêtes PostgreSQL",
    "text": "3.3 Requêtes PostgreSQL\nLes données DRIAS sont également stockées dans une base PostgreSQL qu’il est possible de requêter. La table drias.previsions contient une grille équivalente aux données raster précédemment utilisées. On souhaite obtenir la même visualisation que celle obtenue précédemment en requêtant la base de données. Pour ce faire, utiliser la fonction sf::st_read avec une requête sur la table drias.previsions. Pour la création de la carte, on peut utiliser le package ggplot2 et sa fonction geom_sf.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCode\nquery &lt;- \"\nSELECT *\nFROM drias.previsions\n\"\ndrias_sf &lt;- st_read(cnx, query = query)\n\nggplot() + \n  geom_sf(data = drias_sf, aes(fill = arra), color = NA) +\n  binned_scale(aesthetics = \"fill\", scale_name = \"custom\", \n               palette = ggplot2:::binned_pal(scales::manual_pal(values = rev(palette)[-1])),\n               guide = \"bins\",\n               breaks = breaks)"
  },
  {
    "objectID": "app2.html#appariement-spatial-entre-données-drias-et-rpg",
    "href": "app2.html#appariement-spatial-entre-données-drias-et-rpg",
    "title": "3  Cultures et prévisions climatiques",
    "section": "3.4 Appariement spatial entre données DRIAS et RPG",
    "text": "3.4 Appariement spatial entre données DRIAS et RPG\nOn aimerait associer chaque culture à une évolution en terme de cumul de précipitation. Pour ceci il faut tout d’abord récupérer pour chaque culture la surface des parcelles existantes dans chaque carreau de la grille DRIAS. Pour ceci on peut procéder à un appariement spatial des tables drias.previsions et rpg.parcelles de la base de données. On pourra s’aider de cette page de documentation, et utiliser ST_Intersects.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCode\n# On récupère par carreau de la grille DRIAS la surface pour chaque type de culture\nquery &lt;- \"\nSELECT B.point, code_cultu, Sum(surf_parc) AS surface, B.arra\nFROM rpg.parcelles AS A\nJOIN drias.previsions AS B\nON ST_Intersects(A.geom , B.geometry)\nGROUP BY B.point, B.arra, code_cultu\n\"\nres &lt;- dbSendQuery(cnx, query)\narra_df &lt;- dbFetch(res)\n\narra_df %&gt;% head(10) %&gt;% kable()\n\n\n\n\n\npoint\ncode_cultu\nsurface\narra\n\n\n\n\n5343\nCZH\n78.79\n10.30\n\n\n4803\nBTH\n18.06\n23.71\n\n\n3903\nBTA\n25.21\n-36.38\n\n\n3498\nVRG\n10.59\n0.66\n\n\n5078\nVRN\n0.65\n12.48\n\n\n4939\nORH\n186.01\n10.59\n\n\n3624\nTTH\n90.12\n-13.35\n\n\n4636\nFAG\n0.80\n35.12\n\n\n5108\nJ6S\n5.05\n0.70\n\n\n4640\nVRG\n0.31\n23.72\n\n\n\n\n\n\n\nA ce stade, on a récupéré une table avec la surface par type de culture pour chaque carreau de la grille."
  },
  {
    "objectID": "app2.html#calcul-dindicateurs-par-type-de-culture",
    "href": "app2.html#calcul-dindicateurs-par-type-de-culture",
    "title": "3  Cultures et prévisions climatiques",
    "section": "3.5 Calcul d’indicateurs par type de culture",
    "text": "3.5 Calcul d’indicateurs par type de culture\nOn peut maintenant calculer un écart moyen de cumul de précipitation (d’avril à octobre) par unité de surface pour chaque culture, afin identifier celles qui seront impactées par des baisses de précipitations à horizon proche. Un fichier .csv contenant les intitulés complets des différentes cultures est disponible sur MinIO (bucket \"projet-funathon\", objet \"2023/sujet2/diffusion/ign/rpg/CULTURE.csv\").\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCode\n# Récupération des libellés des codes culture\nculture_mapping &lt;- s3read_using(\n  FUN = read.csv,\n  sep = \";\",\n  object = \"2023/sujet2/diffusion/ign/rpg/CULTURE.csv\",\n  bucket = \"projet-funathon\",\n  opts = list(\"region\" = \"\")\n)\n\n# On aggrège au niveau national par code culture et on calcule un écart\n# moyen du cumul par m2\nagg_arra_df &lt;- arra_df %&gt;%\n  group_by(code_cultu) %&gt;%\n  summarise(ecart_volume_precip = sum(surface * arra), surface = sum(surface)) %&gt;%\n  mutate(ecart_cumul_moyen = ecart_volume_precip / surface)\n\n# Récupération des 10 cultures avec une forte perte de précipitation\nagg_arra_df %&gt;%\n  dplyr::left_join(culture_mapping, by = c(\"code_cultu\" = \"Code\")) %&gt;%\n  arrange(ecart_cumul_moyen) %&gt;%\n  head(10) %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\ncode_cultu\necart_volume_precip\nsurface\necart_cumul_moyen\nLibellé\n\n\n\n\nPVP\n-13726.4694\n346.56\n-39.607772\nPoivron / Piment\n\n\nMID\n-310201.4660\n26283.67\n-11.802061\nMaïs doux\n\n\nSGE\n-24903.3477\n3327.82\n-7.483382\nSauge\n\n\nARA\n-541.0369\n76.50\n-7.072378\nArachide\n\n\nLAV\n105054.4076\n35387.95\n2.968649\nLavande / Lavandin\n\n\nSPH\n6608775.8514\n2041360.68\n3.237437\nSurface pastorale - herbe prédominante et ressources fourragères ligneuses présentes\n\n\nVAL\n107.8679\n31.53\n3.421120\nValériane\n\n\nPAQ\n158.4835\n26.45\n5.991815\nPâquerette\n\n\nCRN\n70.0155\n10.77\n6.500975\nCornille\n\n\nNVH\n180.2147\n25.00\n7.208588\nNavette d’hiver\n\n\n\n\n\n\n\nOn observe que maïs doux est une culture qui va connaître une baisse de cumul de précipitations à horizon proche. Où sont situées les parcelles de maïs doux ? On souhaite dessiner une carte indiquant l’emplacement de ces parcelles. Pour ce faire, faire une requête de la table rpg.parcelles et utiliser ggplot2 et sa fonction geom_sf pour tracer la carte. Pour que les parcelles soient visibles, on pourra artificiellement augmenter leur surface grâce à la fonction st_buffer.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCode\n# Frontières régionales de métropole\nregion_sf &lt;- st_read(\n  cnx, query = \"SELECT * FROM adminexpress.region\"\n)\nregion_sf &lt;- region_sf %&gt;% st_transform(\n  \"EPSG:2154\"\n)\nregion_sf &lt;- region_sf %&gt;%\n  dplyr::filter(!(insee_reg %in% c(\"03\", \"04\", \"06\", \"01\", \"02\", \"01_SBSM\")))\n\n# Parcelles de maïs doux\nquery_mid &lt;- \"\nSELECT id_parcel, geom\nFROM rpg.parcelles\nWHERE code_cultu = 'MID'\n\"\ncultures_mid &lt;- st_read(cnx, query = query_mid)\nggplot() + \n  geom_sf(data = region_sf) +\n  geom_sf(data = st_buffer(cultures_mid, 5000), fill = \"#fca8ab\", color = NA)\n\n\n\n\n\n\n\nOn observe comme attendu beaucoup de parcelles dans le Sud-Ouest où des baisses de précipitations sont attendues à horizon proche."
  },
  {
    "objectID": "app2.html#pour-aller-plus-loin",
    "href": "app2.html#pour-aller-plus-loin",
    "title": "3  Cultures et prévisions climatiques",
    "section": "3.6 Pour aller plus loin",
    "text": "3.6 Pour aller plus loin\nPour aller plus loin, plusieurs idées :\n\nCalculer des écarts en pourcentage par rapport au niveau sur la période de référence pour avoir une idée plus parlante de la diminution ou de l’augmentation du cumul de précipitations;\nRegarder plutôt les prévisions climatiques à long terme, en utilisant la table drias.previsions_hl qui concerne la période 2071-2100;\nS’intéresser aux autres indicateurs qui existent dans les données DRIAS;"
  },
  {
    "objectID": "physio_era5.html#proposition",
    "href": "physio_era5.html#proposition",
    "title": "4  Évolution de la date théorique de récolte",
    "section": "4.1 Proposition",
    "text": "4.1 Proposition\n\n\n\n\n\n\nVotre mission si vous l’acceptez…\n\n\n\nEstimer les tendances de la date potentielle de récolte du maïs grain dans les différents bassins de productions français depuis 1980.\n\n\n\n4.1.1 Compétences mises en œuvre\n\nUtiliser le langage R.\nManipuler des données géographiques : vecteurs et rasters avec les packages {sf}, {terra}, {stars}.\nRequêter en SQL sur PostgreSQL/PostGIS avec {RPostgres} et {sf}.\nUtiliser le lissage spatial pour synthétiser les données géographiques avec {btb}.\nCréer une carte web interactive avec {leaflet}.\nEstimer et visualiser des tendances : modèle linéaire simple et {ggplot2}.\n\n\n\n4.1.2 Données utilisées\n\nLe RPG recense les parcelles déclarées à la PAC (Politique agricole commune) par les agricuteurs : données graphiques et leur culture principale.\nLes données 2021 (environ 10 millions de parcelles) sont disponibles dans une base PostgreSQL/PostGIS.\nERA5 agrometeorological indicators est un jeu de données issu d’un projet de réanalyse météorologique qui vise à uniformiser et corriger les données historiques (ERA5). Il fournit des paramètres agro-météorologiques de surface quotidiens sur les quarante dernières années à une résolution spatiale de 0,1 ° (soit environ 8×11 km en France métropolitaine).\nLes données de température moyenne journalière 1979-2022 (87 Go à l’origine) ont été préchargées sur Minio et limitées à l’emprise de la métropole, représentant au final 16 000 fichiers de 76 ko = 1,1 Go).\nElles sont au format NetCDF. Un package R existe pour importer et requêter ce jeu de données particulier : {ag5Tools}. Les données peuvent aussi être traitées avec les packages de manipulation de rasters tels que {terra} (ou {raster}) et {stars}.\nAdmin Express est le référentiel des limites administratives de l’IGN. Des tables simplifiées des communes et des régions 2023 ont été intégrées dans la base PostgreSQL/PostGIS.\n\n\n\n4.1.3 Scénario\n\nDéfinir les principaux bassins de production du maïs grain à partir du RPG ;\nextraire les températures journalières sur un point central de chaque bassin ;\ncalculer les dates de récolte théoriques pour chaque bassin et chaque année ;\nestimer les tendances par bassin."
  },
  {
    "objectID": "physio_era5.html#préparation",
    "href": "physio_era5.html#préparation",
    "title": "4  Évolution de la date théorique de récolte",
    "section": "4.2 Préparation",
    "text": "4.2 Préparation\nLe pas-à-pas détaillé est décrit sur la page de démarrage, mais en résumé :\n\nSi configuré au lancement de la session RStudio, le pull depuis https://github.com/InseeFrLab/funathon2023_sujet2 a dû être fait.\nOuvrir le projet RStudio funathon2023_sujet2.Rproj.\nRestaurer les packages à utiliser : renv::restore() (11 min).\nSi ce n’est pas déjà fait, il faut avoir préalablement copié les données depuis le stockage MinIO :\nmc cp -r s3/projet-funathon/2023/sujet2/diffusion/era5/ ~/work/funathon2023_sujet2/data/era5/\nPour se connecter à la base PostgreSQL, il faudra avoir défini les bonnes variables d’environnements par exemple en ajoutant PASS_POSTGRESQL = \"xxxx\", etc. dans le fichier ~/.Renviron : file.edit(\"~/.Renviron\") et en ayant relancé la session (ctrl+maj+F10).\n\n\nlibrary(stars)     # manipulation de rasters\nlibrary(terra)     # manipulation de rasters\nlibrary(tidyverse) # manipulation des données\nlibrary(glue)      # interpolation de chaine de caractères\nlibrary(fs)        # gestion du système de fichier\nlibrary(RPostgres) # connexion PostgreSQL\nlibrary(sf)        # manipulation de données spatiales vecteur\nlibrary(leaflet)   # carto web\nlibrary(gt)        # mise en forme tableaux\nlibrary(gtsummary) # tableaux de modèles stat\nlibrary(ggrepel)   # étiquettage graphiques\n# D'autres packages sont à installer et seront appelés directement avec leur\n# namespace : btb, raster, fasterize, rlang, memoise\n\n# localisation des données dans le stockage \"local\"\nrep_era5 &lt;- \"data/era5\"\n\n# pour avoir les noms de dates en français\ninvisible(Sys.setlocale(\"LC_ALL\", \"fr_FR.UTF-8\"))\n\noptions(OutDec = \",\",\n        scipen = 999)\n\n# Connexion à la base PostgreSQL\ncnx &lt;- dbConnect(Postgres(),\n                 user = Sys.getenv(\"USER_POSTGRESQL\"),\n                 password = Sys.getenv(\"PASS_POSTGRESQL\"),\n                 host = Sys.getenv(\"HOST_POSTGRESQL\"),\n                 dbname = \"defaultdb\",\n                 port = 5432,\n                 check_interrupts = TRUE)\n\nVous pouvez vous contenter de la description succinte du scénario ci-dessus pour vous lancer ou poursuivre la lecture pour être plus guidé. Vous pouvez aussi bien sûr afficher le code si vous êtes bloqués, si vous voulez des pistes de démarrage ou si vous souhaitez comparer nos approches."
  },
  {
    "objectID": "physio_era5.html#définition-des-bassins-de-production-du-maïs-grain",
    "href": "physio_era5.html#définition-des-bassins-de-production-du-maïs-grain",
    "title": "4  Évolution de la date théorique de récolte",
    "section": "4.3 Définition des bassins de production du maïs grain",
    "text": "4.3 Définition des bassins de production du maïs grain\n\n\nCode\nsurf_mais &lt;- dbGetQuery(cnx, \"\n  SELECT \n    code_cultu,\n    SUM(surf_parc) AS surf_ha\n  FROM rpg.parcelles\n  WHERE code_cultu IN ('MIS', 'MIE', 'MID')\n  GROUP BY code_cultu\")\n\nsurf_tot_pac &lt;- dbGetQuery(cnx, \"\n  SELECT \n    SUM(surf_parc) AS surf_ha\n  FROM rpg.parcelles\")\n\nsurf &lt;- function(code){\n  surf_mais %&gt;% \n    filter(code_cultu == code) %&gt;% \n    pull(surf_ha)\n}\n\n\nLe maïs grain (code culture : MIS) représente, avec une surface de 1,5·106 ha, la moitié du maïs cultivé2 en France en 2021, soit environ 5 % des surfaces déclarées à la PAC. Il est utilisé pour l’alimentation animale (essentiellement) et humaine, la transformation en amidon, les agrocarburants…2 Les autres cultures étant le maïs ensilage (MIE, 1,28·106 ha, broyé et fermenté) destiné à nourrir le bétail et le maïs doux (MID, environ 23 000 ha) pour l’alimentation humaine.\n→ Pouvez-vous confirmer ces chiffres ? La table rpg.parcelles liste chaque parcelle avec son code_cultu et sa surf_parc en hectare.\nPour déterminer les aires principales de culture on peut, par exemple, extraire les principales zones où la densité de culture du maïs grain est la plus forte. Cela peut se faire par commune, par clustering ou avec un lissage (voir chapitre 8 Loonis et de Bellefon, 2018).\nOn présente ici un exemple avec un lissage filtré mais vous êtes libre d’utiliser une autre méthode pour déterminer ces aires principales, l’objectif étant d’obtenir une dizaine de points représentatifs sur le territoire à partir desquels nous extrairons les données de température.\n\n4.3.1 Récupération des données\n\nLa table rpg.parcelles contient les polygones des parcelles ; le lissage attend un point par parcelle. Il faut donc récupérer une table de points.\nLa table adminexpress.region contient les polygones des régions. Le lissage nécessitera le contour de la France (métropolitaine) pour “fermer” la zone d’étude. Il faudra donc fusionner les régions.\nLa table adminexpress.commune contient les polygones des limites de communes et pourra nous permettre de nommer nos zones en identifiant la commune la plus peuplée de la zone.\n\nNB : pour le lissage, il est recommandé d’utiliser une projection dite “équivalente” (conservant les surfaces), par exemple en France la LAEA Europe, connue sous le code EPSG:3035.\n\n\nCode\n# contour de la métropole (pour limiter le lissage à l'intérieur des frontières)\nfr &lt;- read_sf(cnx, query = \"\n  SELECT \n    st_union(st_transform(geom, 3035)) as geom\n  FROM adminexpress.region\n  WHERE insee_reg &gt; '06'\")\n\n# communes (pour donner ultérieurement un nom à nos bassins de production)\ncom &lt;- read_sf(cnx, query = \"\n  SELECT \n    nom,\n    insee_dep,\n    population,\n    st_transform(geom, 3035) as geom\n  FROM adminexpress.commune\n  WHERE insee_reg &gt; '06'\")\n\n# un point par parcelle de maïs avec sa surface qui servira de poids au lissage\nmais &lt;- read_sf(cnx, query = \"\n  SELECT \n    st_transform(st_pointonsurface(geom), 3035) as geom,\n    surf_parc\n  FROM rpg.parcelles\n  WHERE code_cultu = 'MIS'\")\n\n\n\n\n4.3.2 Lissage\n\n\nCode\nseuil_lissage  &lt;- 8     # seuil de densité à prendre en compte (ha/km²)\nnb_bassins     &lt;- 10    # combien de bassins on conserve\nbande_passante &lt;- 10000 # \"étalement\" du lissage en m\npixel          &lt;- 1000  # taille du pixel en sortie en m\n\n\nPour un rendu à la fois synthétique et esthétique on peut faire un lissage à 10 km de “bande passante” avec un pixel de 1 km.\nLa fonction btb::btb_smooth() attend une table (data.frame) de coordonnées et contenant la variable à lisser, une valeur de bande passante (dans la projection utilisée, donc en mètres dans notre cas) ; on peut optionnellement fournir une grille régulière (data.frame) pour faciliter les comparaisons de jeux de données (en s’assurant qu’ils ont les mêmes emprises et résolutions) et border la zone d’étude.\nEn retour nous obtiendrons un data.frame ; il peut être plus intéressant de rasteriser le résultat.\n\n\nCode\n# Lissage : fonctions simplifiant la création de rasters lissés à partir de \n# points avec {btb}\n#\n# michael.delorme - 2021-08-26\n\n# utils -------------------------------------------------------------------\n\n#' rounding\n#' from plyr\n#'\n#' @param x\n#' @param accuracy\n#' @param f\n#'\n#' @return\nround_any &lt;- function(x, accuracy, f = round) {\n  \n  f(x / accuracy) * accuracy\n}\n\n#' Generate a grid of coordinates from a spatial layer\n#'\n#' Memoised to get a faster result when used multiple times on the same extent\n#'\n#' @param zone sf object (polygons) : spatial extent\n#' @param margin number : buffer of bounding box\n#' @param resolution number : distance between nodes\n#'\n#' @return dataframe of coordinates (x, y)\ngenerate_grid &lt;- memoise::memoise(function(zone, margin, resolution) {\n  \n  zone_bbox &lt;- sf::st_bbox(zone)\n  \n  zone %&gt;%\n    sf::st_make_grid(cellsize = resolution,\n                     offset = c(round_any(zone_bbox[1] - margin, resolution, floor),\n                                round_any(zone_bbox[2] - margin, resolution, floor)),\n                     what = \"centers\") %&gt;%\n    sf::st_sf() %&gt;%\n    sf::st_join(zone, join = st_intersects, left = FALSE) %&gt;%\n    sf::st_coordinates() %&gt;%\n    tibble::as_tibble() %&gt;%\n    dplyr::select(x = X, y = Y)\n})\n\n\n# main function -----------------------------------------------------------\n\n#' Kernel weighted smoothing with arbitrary bounding area\n#'\n#' @param df sf object (points) : features to smooth\n#' @param field expression : weight field in df (unquoted) ; the values must not have NAs\n#' @param bandwidth numeric : kernel bandwidth (output map units)\n#' @param resolution numeric : output grid resolution (output map units)\n#' @param zone sf objet (polygons) : study zone boundary. If null will use df extent\n#' @param out_crs integer : EPSG code projection for output raster (should be an equal-area projection)\n#' @param ... other arguments passed to btb::kernelSmoothing\n#'\n#' @return a raster object\n#' @export\n#' @import btb, raster, fasterize, dplyr, sf, rlang, memoise\nlissage &lt;- function(df, field, bandwidth, resolution, zone = NULL, out_crs = 3035, ...) {\n  \n  field_name &lt;- rlang::as_name(rlang::enquo(field))\n  \n  if (!\"sf\" %in% class(df)\n      | sf::st_geometry_type(df, FALSE) != \"POINT\") {\n    stop(\"« df » should be a point sf object.\")\n  }\n  \n  if (!is.numeric(bandwidth)) stop(\"bandwidth sould be numeric.\")\n  if (!is.numeric(resolution)) stop(\"resolution sould be numeric.\")\n  \n  nb_na &lt;- sum(is.na(dplyr::pull(df, {{field}})))\n  if (nb_na &gt; 0) {\n    warning(paste(\"removing\", nb_na, \"NA\",\n                  paste0(\"value\", ifelse(nb_na &gt; 1, \"s\", \"\")),\n                  \"in «\", field_name, \"»...\"))\n    df &lt;- tidyr::drop_na(df, {{field}}) %&gt;%\n      sf::st_as_sf()\n  }\n  \n  # check projections\n  if (is.na(sf::st_crs(df))) {\n    stop(\"missing projection in sf object « df ».\")\n  }\n  \n  if (sf::st_crs(df)$epsg != out_crs) {\n    message(\"reprojecting data...\")\n    df &lt;- sf::st_transform(df, out_crs)\n  }\n  \n  if (!is.null(zone)) {\n    if (!\"sf\" %in% class(zone)\n        |!sf::st_geometry_type(zone, FALSE) %in% c(\"POLYGON\", \"MULTIPOLYGON\")) {\n      stop(\"« zone » should be a polygon/multiploygon sf object.\")\n    }\n    \n    # check projections\n    if (is.na(sf::st_crs(zone))) {\n      stop(\"missing projection in sf object « zone ».\")\n    }\n    \n    if (sf::st_crs(zone)$epsg != out_crs) {\n      message(\"reprojecting study zone...\")\n      zone &lt;- sf::st_transform(zone, out_crs)\n    }\n    \n    # grid generation\n    if (memoise::has_cache(generate_grid)(zone, bandwidth, resolution)) {\n      message(\"retrieving reference grid from cache...\")\n    } else {\n      message(\"generating reference grid...\")\n    }\n    \n    zone_xy &lt;- generate_grid(zone, bandwidth, resolution)\n    zone_bbox &lt;- sf::st_bbox(zone)\n    \n  } else {\n    message(\"using default reference grid...\")\n    \n    zone_xy &lt;- NULL\n    zone_bbox &lt;- sf::st_bbox(df)\n  }\n  \n  # kernel\n  message(paste0(\"computing kernel on « \", field_name, \" »...\"))\n  kernel &lt;- df %&gt;%\n    bind_cols(., sf::st_coordinates(.) %&gt;% # si pas de données renvoie vecteur non nommé\n                as.data.frame() %&gt;%     # donc on le modifie\n                set_names(c(\"x\", \"y\"))) %&gt;%\n    sf::st_drop_geometry() %&gt;%\n    dplyr::select(x, y, {{ field }}) %&gt;%\n    btb::btb_smooth(sEPSG = out_crs,\n                    iCellSize = resolution,\n                    iBandwidth = bandwidth,\n                    dfCentroids = zone_xy, ...)\n  \n  # rasterization\n  message(\"\\nrasterizing...\")\n  raster::raster(xmn = round_any(zone_bbox[1] - bandwidth, resolution, floor),\n                 ymn = round_any(zone_bbox[2] - bandwidth, resolution, floor),\n                 xmx = round_any(zone_bbox[3] + bandwidth, resolution, ceiling),\n                 ymx = round_any(zone_bbox[4] + bandwidth, resolution, ceiling),\n                 resolution = resolution,\n                 crs = sf::st_crs(out_crs)$input\n  ) %&gt;%\n    fasterize::fasterize(kernel, ., field = field_name)\n}\n\n\n\n\n\nCode\nmais_liss &lt;- mais %&gt;% \n  lissage(surf_parc, bandwidth = bande_passante, resolution = pixel, zone = fr) %&gt;% \n  rast()\n\n\n\n\nCode\nplot(mais_liss, main = \"Densité de culture de maïs grain 2021 (ha/km²)\")\n\n\n\n\n\nFigure 4.2 –  Lissage\n\n\n\n\nOn peut garder par exemple les densités supérieures à 8 ha/km² et on conservera les 10 plus grandes zones, que nous nommerons avec le nom de la plus grande ville de la zone.\n\n\nCode\nplot(mais_liss &gt; seuil_lissage, main = glue(\"Zones de culture de maïs grain 2021 (&gt; {seuil_lissage} ha/km²)\"))\n\n\n\n\n\nFigure 4.3 –  Lissage filtré\n\n\n\n\nSuggestions :\n\nfiltrer le raster ;\nvectoriser le raster en polygones ;\ncalculer les surfaces ;\nconserver les plus grands polygones ;\nfaire une jointure spatiale avec les points des communes ;\ndéterminer la plus grande commune de chaque polygone et le nommer.\n\nNB : Le centroïde d’un polygone tarabiscoté peut se trouver en dehors du polygone ; on utilise st_point_on_surface() plutôt que st_centroid() pour garantir qu’il est bien dans le polygone.\n\n\nCode\n# vectorisation et conservation des nb_bassins + grandes zones\ncluster_liss &lt;- (mais_liss &gt; seuil_lissage) %&gt;% \n  as.polygons() %&gt;% \n  st_as_sf() %&gt;% \n  filter(layer == 1) %&gt;% \n  st_cast(\"POLYGON\") %&gt;% \n  mutate(surf = st_area(geometry)) %&gt;% \n  slice_max(surf, n = nb_bassins) %&gt;% \n  mutate(id = row_number())\n\n# nommage des clusters avec le nom de la plus grosse ville de la zone\nnoms &lt;- cluster_liss %&gt;% \n  st_join(st_point_on_surface(com), left = TRUE) %&gt;% \n  st_drop_geometry() %&gt;% \n  group_by(id) %&gt;% \n  slice_max(population, n = 1, with_ties = FALSE) %&gt;% \n  select(id, nom, insee_dep)\n\n\nLa couche résultante peut-être affichée sur une carte interactive avec {leaflet}.\n\n\nCode\ncluster_liss %&gt;% \n  inner_join(noms, by = \"id\") %&gt;% \n  st_transform(\"EPSG:4326\") %&gt;% \n  leaflet() %&gt;% \n  addPolygons(popup = ~ glue(\"{id}. bassin de {nom}\")) %&gt;% \n  addTiles()\n\n\n\n\n\nFigure 4.4 –  Les 10 bassins de production retenus"
  },
  {
    "objectID": "physio_era5.html#extraction-des-températures-à-chaque-point",
    "href": "physio_era5.html#extraction-des-températures-à-chaque-point",
    "title": "4  Évolution de la date théorique de récolte",
    "section": "4.4 Extraction des températures à chaque point",
    "text": "4.4 Extraction des températures à chaque point\nPour chaque bassin de production, on va rechercher un point représentatif et récupérer les données de température journalières pour tous ces points.\nLe package {stars} est bien adapté à la manipulation des données spatio-temporelles.\n\n\nCode\n# préparations de points pour l'extraction des températures. \npoints &lt;- cluster_liss %&gt;% \n  inner_join(noms, by = \"id\") %&gt;% \n  st_point_on_surface() %&gt;% \n  st_transform(\"EPSG:4326\")\n\n# données de température sous forme de pile de rasters\nera5 &lt;- dir_ls(here::here(rep_era5), recurse = TRUE, glob = \"*.nc\") %&gt;% \n  read_stars() %&gt;% \n  rename(temp_moy_k = 1)\n\n# extraction\ntemp_points &lt;- era5 %&gt;% \n  st_extract(points) %&gt;%\n  as_tibble() %&gt;% \n  mutate(temp_moy_c = temp_moy_k - 273.15,\n         date = as_date(time)) %&gt;% \n  full_join(points, ., by = \"geometry\")\n\n\n\n\n\n\n\n\nTableau 4.1 –   Températures moyennes journalières (extrait) \n  \n    \n    \n      date\n      bassin de production\n      température moy. (°C)\n    \n  \n  \n    1979-01-01\nPau\n\n4,5916992\n    1979-01-02\nPau\n\n-0,9852356\n    1979-01-03\nPau\n\n0,9097839\n    1979-01-04\nPau\n\n8,4750000\n    1979-01-05\nPau\n\n5,8669678\n    1979-01-06\nPau\n\n5,0254761\n    ...\netc.\n\n..."
  },
  {
    "objectID": "physio_era5.html#calcul-des-degrés-jour-et-des-dates-de-récolte",
    "href": "physio_era5.html#calcul-des-degrés-jour-et-des-dates-de-récolte",
    "title": "4  Évolution de la date théorique de récolte",
    "section": "4.5 Calcul des degrés jour et des dates de récolte",
    "text": "4.5 Calcul des degrés jour et des dates de récolte\n\n\nCode\n# base de calcul pour maïs : 6 °C\nbase &lt;- 6 # °C\n\n# besoin total à récolte pour un maïs grain de précocité moyenne : 1700 DJ\nbesoin &lt;- 1700 # DJ\n\n\n\\[DJ_{n} = \\sum_{j=1}^{n}{\\frac{T_{max, j} - T_{min, j}}{2} - T_{base}}\\]\nLe maïs a une température de base de 6 °C et il lui faut 1700 DJ (variable selon la précocité de la variété) pour être récolté pour le grain3. Les températures supérieures à 30 °C stoppent le développement végétatif. Le semis commence fin mars et est réalisé à 50 % mi-avril4.3 Spotifarm4 Céré’Obs. FranceAgrimer &gt; Rapport Céré’Obs\nOn considère que la température moyenne journalière ERA5 correspond bien à \\(\\frac{T_{max} - T_{min}}{2}\\).\nNB : la date n’est pas un bon indicateur pour suivre précisémment une évolution journalière à cause des années bissextiles. Par exemple le 15 avril ne correspondra pas toujours au même nombre de jours dans l’avancement de la saison de végétation :\n\nyday(ymd(\"2020-04-15\"))\n\n[1] 106\n\nyday(ymd(\"2023-04-15\"))\n\n[1] 105\n\n\nCela peut-être impactant si on recherche des tendances qui sont de l’ordre de grandeur du jour. On utilisera donc le jour de l’année (day of year ou doy).\n\n\nCode\nrecolte &lt;- temp_points %&gt;% \n  select(date, nom, temp_moy_c) %&gt;% \n  group_by(nom, annee = year(date)) %&gt;% \n  mutate(dj = case_when(yday(date) &lt; 105 ~ 0,\n                        temp_moy_c &gt;= 30 ~ 0,\n                        temp_moy_c &lt; base ~ 0,\n                        TRUE ~ temp_moy_c - base),\n         sdj = cumsum(dj),\n         doy = yday(date)) %&gt;%\n  filter(sdj &gt; besoin) %&gt;% \n  slice_min(date) %&gt;% \n  ungroup() %&gt;% \n  select(date, annee, doy, nom)\n\n\n\n\n\n\n\n\nTableau 4.2 –   Dates de récolte potentielles (extrait) \n  \n    \n    \n      date\n      année\n      jour (doy)\n      bassin de production\n    \n  \n  \n    1979-09-26\n1979\n269\nChalon-sur-Saône\n\n    1980-10-04\n1980\n278\nChalon-sur-Saône\n\n    1979-10-30\n1979\n303\nLe Lude\n\n    1980-11-16\n1980\n321\nLe Lude\n\n    1979-09-24\n1979\n267\nLuçon\n\n    1980-09-28\n1980\n272\nLuçon\n\n    1979-09-13\n1979\n256\nMarmande\n\n    1980-09-19\n1980\n263\nMarmande\n\n    1979-10-29\n1979\n302\nMeung-sur-Loire\n\n    1980-11-18\n1980\n323\nMeung-sur-Loire\n\n    1979-10-08\n1979\n281\nMulhouse\n\n    1981-10-09\n1981\n282\nMulhouse\n\n    1979-09-18\n1979\n261\nPau\n\n    1980-09-25\n1980\n269\nPau\n\n    1979-12-05\n1979\n339\nPontivy\n\n    1981-11-20\n1981\n324\nPontivy\n\n    1979-12-08\n1979\n342\nQuimperlé\n\n    1981-11-19\n1981\n323\nQuimperlé\n\n    1979-09-21\n1979\n264\nSaintes\n\n    1980-09-26\n1980\n270\nSaintes\n\n    ...\n...\n...\netc."
  },
  {
    "objectID": "physio_era5.html#tendances",
    "href": "physio_era5.html#tendances",
    "title": "4  Évolution de la date théorique de récolte",
    "section": "4.6 Tendances",
    "text": "4.6 Tendances\n\n4.6.1 Visualisation des tendances\n\n\nCode\nmod_interactions &lt;- recolte %&gt;% \n  glm(doy ~ annee * nom, data = .)\n\n# préparation des étiquettes pour la visualisation avec affichage direct (sans \n# légende)\netiquettes &lt;- tibble(nom = unique(recolte$nom),\n                     annee = max(recolte$annee) + 1) %&gt;% \n  bind_cols(doy = predict(mod_interactions, newdata = .)) %&gt;% \n  mutate(date_virtuelle = as_date(parse_date_time(glue(\"2020-{str_pad(round(doy, 0), 3, 'left', '0')}\"), \n                                                  orders = \"yj\")))\n\n\n\n\nCode\nrecolte %&gt;% \n  mutate(date_virtuelle = as_date(parse_date_time(glue(\"2020-{str_pad(doy, 3, 'left', '0')}\"), \n                                                  orders = \"yj\"))) %&gt;% \n  ggplot(aes(annee, date_virtuelle, color = nom)) +\n  geom_point() +\n  geom_smooth(method = glm) +\n  geom_text_repel(data = etiquettes, \n                  aes(label = str_wrap(nom, 10, whitespace_only = FALSE)),\n                  nudge_x = 1.5, size = 3, direction = \"y\", lineheight = 0.6) +\n  scale_y_date(date_breaks = \"months\", date_labels = \"%b\") +\n  coord_cartesian(xlim = c(min(recolte$annee) - .5, max(recolte$annee) + 5),\n                  ylim = as.Date(c(NA, \"2020-11-15\")),\n                  expand = FALSE) +\n  labs(title = \"Date de récolte potentielle\",\n       subtitle = \"Maïs grain, par bassin de production\",\n       x = \"année\",\n       y = \"jour\",\n       caption = glue(\"d'après données agroclimatiques ERA5\n                       pour une précocité moyenne ({besoin} DJ, base {base} °C)\")) +\n  theme(legend.position = \"none\",\n        plot.caption = element_text(size = 6))\n\n\n\n\n\nFigure 4.5 –  Évolution de la date de récolte potentielle du maïs grain\n\n\n\n\n\n\n4.6.2 Paramètres des tendances\n\n\nCode\nmod_simple &lt;- recolte %&gt;% \n  glm(doy ~ annee + nom, data = .)\n\nevol &lt;- round(mod_simple$coefficients[[\"annee\"]], 1)\nic95 &lt;- round(confint(mod_simple)[2, ], 1)\nr2 &lt;- round(with(summary(mod_simple), 1 - deviance / null.deviance), 2)\n\n# Pour les bayesiens\n#\n# library(rstanarm)\n# library(bayestestR)\n#\n# mod_bayes &lt;- recolte %&gt;%\n#   stan_glm(doy ~ annee + nom, data = .)\n# \n# describe_posterior(mod_bayes, ci = .95, rope_range = c(-.05, 0.5))\n\n\nAu cours des quatre dernières décennies, la date de récolte potentielle moyenne du maïs grain dans les principaux bassins de production français à évolué d’environ -0,7 jour par an (IC95 % [-0,8 ; -0,6], r2 = 0,75).\n\n\nCode\nset_gtsummary_theme(list(\"pkgwide-str:ci.sep\" = \" – \"))\ntheme_gtsummary_language(\"fr\")\n\nmod_simple %&gt;% \n  tbl_regression(label = list(annee ~ \"année\",\n                              nom ~ \"bassin de production\")) %&gt;% \n  as_gt() %&gt;%\n  tab_source_note(source_note = glue(\"Maïs grain France \n                                      {min(recolte$annee)}-{max(recolte$annee)} \n                                      d'après données agroclimatiques ERA5 pour \n                                      une précocité moyenne ({besoin} DJ, base\n                                      {base} °C)\"))\n\n\n\n\n\n\nTableau 4.3 –   Évolution de la date de récolte : environ -0,7 jour par an \n  \n    \n    \n      Caractéristique\n      Beta\n      95% IC1\n      p-valeur\n    \n  \n  \n    année\n-0,67\n-0,76 – -0,58\n&lt;0,001\n    bassin de production\n\n\n\n        Chalon-sur-Saône\n—\n—\n\n        Le Lude\n21\n16 – 26\n&lt;0,001\n        Luçon\n1,1\n-3,9 – 6,1\n0,7\n        Marmande\n-9,2\n-14 – -4,2\n&lt;0,001\n        Meung-sur-Loire\n20\n15 – 25\n&lt;0,001\n        Mulhouse\n8,7\n3,6 – 14\n&lt;0,001\n        Pau\n-3,6\n-8,6 – 1,4\n0,2\n        Pontivy\n46\n41 – 51\n&lt;0,001\n        Quimperlé\n48\n43 – 54\n&lt;0,001\n        Saintes\n-0,11\n-5,1 – 4,9\n&gt;0,9\n  \n  \n    \n      Maïs grain France \n1979-2022 \nd'après données agroclimatiques ERA5 pour \nune précocité moyenne (1700 DJ, base\n6 °C)\n    \n  \n  \n    \n      1 IC = intervalle de confiance\n    \n  \n\n\n\n\n\n\n\n4.6.3 Validation\nDes données d’observation ponctuelles permettent de confronter notre modèle à la réalité (de La Torre et Benoît, 2004) :\nÀ Toulouse (proche du bassin de Pau) sur 1977-2003, la “date de semis passe de début mai à début avril en 20 ans”. […] “Cet écart au semis ne se retrouve pas à la récolte (très variable entre la mi-septembre et la mi-octobre), d’une part parce que le choix des semences a glissé vers des variétes un peu plus tardives (…) et/ou d’autre part, parce que le grain récolté est plus sec (« pour tenir compte de l’augmentation du coût de séchage »)”. […] “Le cycle de culture a augmenté d’une dizaine de jours depuis 1977 ; il est d’environ 160 jours”.\nAinsi, même si on voit que la variété utilisée a probablement un impact important et que des changements de techniques culturales ont eu lieu, une précocité de semis d’un mois combinée à 10 jours de culture de plus représente, pour cet exemple, une date de récolte de -0,8 jour par an, ce qui n’est pas très éloigné de notre estimation globale.\n\n\n\n\n\n\nDe La Torre C., Benoît M. Changement climatique et observations à long-terme en Unités Expérimentales : évolution des pratiques agricoles et des réponses physiologiques des couverts végétaux. Etude de faisabilité. Mirecourt : INRA-SAD, 2004.\n\n\nLoonis V., De Bellefon M.-P. Manuel d’analyse spatiale. Théorie et mise en œuvre pratique avec R. Montrouge : INSEE - Eurostat, 2018. (Insee Méthodes, 131) ISBN : 978-2-11-139684-5."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Références",
    "section": "",
    "text": "De La Torre C., Benoît M. Changement climatique et\nobservations à long-terme en Unités Expérimentales : évolution des\npratiques agricoles et des réponses physiologiques des couverts\nvégétaux. Etude de faisabilité. Mirecourt :\nINRA-SAD, 2004.\n\n\nLoonis V., De Bellefon M.-P. Manuel d’analyse spatiale.\nThéorie et mise en œuvre pratique avec R.\nMontrouge : INSEE - Eurostat, 2018.\n(Insee Méthodes, 131) ISBN : 978-2-11-139684-5."
  }
]